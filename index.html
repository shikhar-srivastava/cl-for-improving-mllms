<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Improving MLLMs with Continual Learning">
  <meta property="og:title" content="Improving Multimodal Large Language Models Using Continual Learning"/>
  <meta property="og:description" content="This study investigates using continual learning to mitigate linguistic forgetting in Multimodal Large Language Models (MLLMs), enhancing visual understanding while preserving language skills."/>
  <meta property="og:url" content="YOUR_URL_HERE"/>

  <meta property="og:image" content="static/images/banner/mllm_cl_big_webpage.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
  
  <meta name="twitter:title" content="Improving Multimodal Large Language Models Using Continual Learning">
  <meta name="twitter:description" content="This study investigates using continual learning to mitigate linguistic forgetting in Multimodal Large Language Models (MLLMs), enhancing visual understanding while preserving language skills.">
  <meta name="twitter:image" content="static/images/banner/mllm_cl_big_webpage.png">
  <meta name="twitter:card" content="summary_large_image">
  
  <meta name="keywords" content="Continual Learning, Multimodal Large Language Models, MLLM, LLM, Catastrophic Forgetting, LLaVA">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Improving MLLMs with Continual Learning</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" sizes="180x180" href="static/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="static/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="static/images/favicon-16x16.png">
  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link href="https://fonts.googleapis.com/css2?family=Latin+Modern+Roman:wght@400;700&display=swap" rel="stylesheet">
  
  <style>
    .hero .title, .hero .subtitle, .title, .subtitle {
      font-family: 'Latin Modern Roman', serif;
    }
    
    /* Reduce spacing between hero sections */
    .hero {
      padding-bottom: 0;
    }
    
    .hero.teaser {
      padding-top: 0;
      margin-top: -3rem;
    }
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Improving Multimodal Large Language Models Using Continual Learning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.cs.rochester.edu/u/ssrivas9/" target="_blank"><b>Shikhar Srivastava</b></a><sup>1*</sup>,
            </span>
            <span class="author-block">
              <a href="https://yousuf907.github.io/" target="_blank"><b>Md Yousuf Harun</b></a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://robikshrestha.com" target="_blank"><b>Robik Shrestha</b></a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://chriskanan.com" target="_blank"><b>Christopher Kanan</b></a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup> University of Rochester</span>
            <span class="author-block"><sup>2</sup> Rochester Institute of Technology</span>
          </div>
          <div class="is-size-6 publication-authors" style="margin-top: 0.5rem;">
            <span class="author-block">
                <small><sup>*</sup>Corresponding author: <a href="mailto:shikhar.srivastava@rochester.edu">shikhar.srivastava@rochester.edu</a></small>
            </span>
          </div>

                     <div class="is-flex is-justify-content-center is-align-items-center" style="gap: 1rem; margin-top: 1.5rem; flex-wrap: wrap;">
             <div class="tags has-addons" style="margin: 0;">
               <span class="tag is-dark is-medium">
                 <span class="icon"><i class="fas fa-award"></i></span>
                 <span>CoLLAs 2025</span>
               </span>
               <span class="tag is-light is-medium">Conference</span>
             </div>
             <div class="tags has-addons" style="margin: 0;">
               <span class="tag is-dark is-medium">
                 <span class="icon"><i class="fas fa-award"></i></span>
                 <span>SCFM, NeurIPS 2024</span>
               </span>
               <span class="tag is-light is-medium">Workshop</span>
             </div>
           </div>
              <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="#" class="external-link button is-normal is-rounded is-dark" style="opacity: 0.5; pointer-events: none;">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code (Coming Soon)</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2410.19925" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="ai ai-arxiv"></i></span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://lifelong-ml.cc/Conferences/2025/acceptedpapersandvideos/conf-2025-8" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-play"></i></span>
                    <span>Presentation</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <img class="rounded" src="static/images/banner/mllm_cl_big_webpage.png" alt="A diagram showing how continual learning can be used to improve multimodal large language models by mitigating catastrophic forgetting of linguistic abilities." style="display: block; margin-left: auto; margin-right: auto; width: 95%;">
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2 has-text-centered">Abstract</h2>
        <div class="content has-text-justified">
            <p>
            Generative large language models (LLMs) exhibit impressive capabilities, which can be further augmented by integrating a pre-trained vision model into the original LLM to create a multimodal LLM (MLLM). However, this integration often significantly decreases performance on natural language understanding and generation tasks, compared to the original LLM. This study investigates this issue using the LLaVA MLLM, treating the integration as a continual learning problem. We evaluate five continual learning methods to mitigate forgetting and identify a technique that enhances visual understanding while minimizing linguistic performance loss. Our approach reduces linguistic performance degradation by up to 15% over the LLaVA recipe, while maintaining high multimodal accuracy. We also demonstrate the robustness of our method through continual learning on a sequence of vision-language tasks, effectively preserving linguistic skills while acquiring new multimodal capabilities.
            </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2 has-text-centered">Motivation ðŸ¤”</h2>
        <div class="content has-text-justified">
          <p>
          A practical MLLM must excel in both text-only and vision-language tasks, as users often switch between these modalities in real-world interactions. Strong linguistic understanding is crucial even for multimodal prompts. We frame this challenge as a <strong>Continual Learning (CL)</strong> problem to mitigate the "catastrophic forgetting" of language skills that occurs when adding visual capabilities. The significant distributional shift from text-only to multimodal contexts makes CL a natural fit for preserving the model's original linguistic prowess.
          </p>
          <p>
          Furthermore, a robust system must continuously learn new multimodal skills without forgetting prior linguistic or visual knowledge. We model this by treating the LLM's initial text training as the first task, followed by a sequence of new vision-language tasks. This allows us to evaluate the incremental acquisition of multimodal skills while ensuring core linguistic abilities are preserved, leading to more versatile and reliable MLLMs.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-12">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page. This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>